{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch_geometric.nn as pyg_nn\n",
    "# from prompt_dt.graph_prompt_decision_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "num_heads = 1\n",
    "dropout = 1e-5\n",
    "n_layers = 3\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG Graph Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([30375, 128])\n",
      "edge shape: torch.Size([2, 399159])\n",
      "torch.cuda.memory_allocated: 2.175523GB\n",
      "torch.cuda.memory_reserved: 2.398438GB\n",
      "torch.cuda.max_memory_reserved: 2.398438GB\n"
     ]
    }
   ],
   "source": [
    "pyg_graph_transformer = nn.ModuleList([Block(hidden_size, hidden_size, num_heads=num_heads, dropout=dropout, layer_norm=True, batch_norm=False) for _ in range(n_layers)])\n",
    "pyg_graph_transformer.to(device)\n",
    "x = torch.load('ant_sample_x.pt')\n",
    "edge = torch.load('ant_sample_edge.pt')\n",
    "print(f'x shape: {x.shape}')\n",
    "print(f'edge shape: {edge.shape}')\n",
    "for block in pyg_graph_transformer:\n",
    "    x = block(x, edge_index=edge)\n",
    "\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(1)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(1)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(1)/1024/1024/1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Transformer with Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(hidden_size, num_heads, dim_feedforward=hidden_size*2, dropout=0, layer_norm_eps=1e-05, batch_first=True)\n",
    "torch_graph_transformer = nn.TransformerEncoder(encoder_layer, 3)\n",
    "# torch_graph_transformer.to(device)\n",
    "# x = torch.load('ant_sample_transformer_inputs.pt')\n",
    "# print(f'x shape: {x.shape}')\n",
    "# out = torch_graph_transformer(x)\n",
    "\n",
    "# print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(1)/1024/1024/1024))\n",
    "# print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(1)/1024/1024/1024))\n",
    "# print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(1)/1024/1024/1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study bool tensor for transformer input mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "structural_mask = torch.ones(5, 5).to(torch.bool)\n",
    "temporal_mask = torch.zeros(5, 5).to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [structural_mask for i in range(10)]\n",
    "a = torch.stack(a, dim=0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 3],\n",
       "        [0, 6],\n",
       "        [3, 3],\n",
       "        [3, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask = [1, 1, 1]\n",
    "num_node = 3\n",
    "a = torch.triu(torch.ones(3, 3), diagonal=0)\n",
    "a = a.nonzero()*num_node\n",
    "b = torch.ones(9, 9).to(torch.bool)\n",
    "temporal_mask = torch.ones(9, 9).to(torch.bool)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ant_dir direction distribution, cheetah_vel velocity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.20336059, 0.42663053, 4.94477548, 4.12386514, 4.00566193,\n",
       "       3.61661964, 0.24543954, 2.24820918, 5.9419027 , 0.37727185,\n",
       "       5.42893665, 5.51217894, 0.32165929, 4.09926706, 3.46675609,\n",
       "       3.75428649, 3.03809995, 1.77806705, 1.87066586, 3.5280645 ,\n",
       "       2.48843943, 4.95555271, 2.62941494, 0.904175  , 0.94817473,\n",
       "       0.34709164, 4.51156075, 1.83668411, 1.24893307, 5.22361358,\n",
       "       3.56879346, 0.5173559 , 3.42432703, 0.99876725, 4.25222348,\n",
       "       0.74438319, 2.79599274, 5.57935818, 5.00938089, 0.42712295,\n",
       "       6.03680751, 4.14190964, 4.51620333, 4.67203061, 5.577812  ,\n",
       "       0.84160545, 4.88187527, 5.26525596, 5.21067551, 0.18319881])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'ant_dir'\n",
    "tasks = []\n",
    "for idx in range(50):\n",
    "    task_paths = f\"config/{env_name}/config_{env_name}_task{idx}.pkl\"   \n",
    "    with open(task_paths.format(idx), 'rb') as f:\n",
    "        task_info = pickle.load(f)\n",
    "        tasks.append(task_info[0]['goal'])\n",
    "\n",
    "tasks = np.array(tasks)\n",
    "tasks\n",
    "# sorted_tasks = np.sort(tasks)\n",
    "# np.diff(sorted_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.86290927, 2.75755456, 5.39472984, 4.38169255, 0.59173373,\n",
       "       6.13001603, 4.78238179, 4.93898769, 0.80496169, 2.82985831,\n",
       "       2.3297927 , 5.82303616, 4.04552386, 5.16956368, 2.78605358,\n",
       "       1.427783  , 3.48455899, 0.40097565, 5.20016002, 3.96886447,\n",
       "       4.76320575, 2.22755235, 6.09907556, 5.61164551, 4.89072775,\n",
       "       1.22295107, 2.93249455, 0.27522718, 0.96942947, 4.29172315,\n",
       "       4.67947864, 6.07904294, 2.0472211 , 2.32766698, 2.95030617,\n",
       "       1.19048366, 0.81632089, 2.9889422 , 1.42571349, 4.20856545,\n",
       "       2.74670651, 5.23187141, 4.3998954 , 1.96265749, 5.22924256,\n",
       "       5.05648359, 2.43459846, 1.81161891, 4.28824572, 0.87809075])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "tasks = 2 * np.pi * rng.random(50)\n",
    "tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention mask for torch graph transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(int(a.sum()))\n",
    "print(len(a))\n",
    "len(a) - int(a.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temporal_mask_list(num_node, max_length, prompt_length):\n",
    "    temporal_masks = []\n",
    "    for num_zeros in range(max_length):\n",
    "        temporal_edge = torch.tril(torch.ones(max_length + prompt_length, max_length + prompt_length), diagonal=0)\n",
    "        temporal_edge[:, prompt_length:prompt_length+num_zeros] = 0\n",
    "        temporal_edge[prompt_length:prompt_length+num_zeros, :] = 0\n",
    "        temporal_edge = temporal_edge.nonzero()*num_node\n",
    "        full_temporal_edge = torch.cat([temporal_edge+i for i in range(num_node)], dim=0)\n",
    "        temporal_mask = torch.zeros(num_node * (max_length + prompt_length), num_node * (max_length + prompt_length))\n",
    "        for edge in full_temporal_edge:\n",
    "            temporal_mask[edge[0], edge[1]] = 1\n",
    "        temporal_mask[:num_node * prompt_length, :num_node * prompt_length] = 0\n",
    "        \n",
    "        temporal_masks.append(temporal_mask)\n",
    "\n",
    "    return temporal_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "num_node = 3\n",
    "max_length = 3\n",
    "prompt_length = 2\n",
    "a = get_temporal_mask_list(num_node, max_length, prompt_length)\n",
    "for a_ in a:\n",
    "    print(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_config(name):\n",
    "    if name == 'halfcheetah':\n",
    "        agent = {\n",
    "            'state_dim': 17,\n",
    "            'act_dim': 6,\n",
    "            'num_node': 7,\n",
    "            'node_type_state_action_len': {\n",
    "                'root': 5,\n",
    "                'thigh': 3,\n",
    "                'shin': 3,\n",
    "            },\n",
    "            'node_type': {\n",
    "                'root': 'root',\n",
    "                'back_thigh': 'thigh',\n",
    "                'back_shin': 'shin',\n",
    "                'bach_foot': 'foot',\n",
    "                'front_thigh': 'thigh',\n",
    "                'front_shin': 'shin',\n",
    "                'front_foot': 'foot',\n",
    "            },\n",
    "            'state_position': {\n",
    "                'root': [0, 1, 8, 9, 10],\n",
    "                'back_thigh': [2, 11],\n",
    "                'back_shin': [3, 12],\n",
    "                'bach_foot': [4, 13],\n",
    "                'front_thigh': [5, 14],\n",
    "                'front_shin': [6, 15],\n",
    "                'front_foot': [7, 16],\n",
    "            },\n",
    "            'action_position': {\n",
    "                'root': [],\n",
    "                'back_thigh': [0],\n",
    "                'back_shin': [1],\n",
    "                'bach_foot': [2],\n",
    "                'front_thigh': [3],\n",
    "                'front_shin': [4],\n",
    "                'front_foot': [5],\n",
    "            },\n",
    "            'edge': [[3, 2], [2, 1], [1, 0], [0, 4], [4, 5], [5, 6]],\n",
    "        }\n",
    "    elif name == 'ant': \n",
    "        agent = {\n",
    "            'state_dim': 27,\n",
    "            'act_dim': 8,\n",
    "            'num_node': 9,\n",
    "            'node_type_state_action_len': {\n",
    "                'root': 11,\n",
    "                'hip': 3,\n",
    "                'ankle': 3,\n",
    "            },\n",
    "            'node_type': {\n",
    "                'root': 'root',\n",
    "                'hip_1': 'hip',\n",
    "                'ankle_1': 'ankle',\n",
    "                'hip_2': 'hip',\n",
    "                'ankle_2': 'ankle',\n",
    "                'hip_3': 'hip',\n",
    "                'ankle_3': 'ankle',\n",
    "                'hip_4': 'hip',\n",
    "                'ankle_4': 'ankle',\n",
    "            },\n",
    "            'state_position': {\n",
    "                'root': [0, 1, 2, 3, 4, 13, 14, 15, 16, 17, 18],\n",
    "                'hip_1': [5, 19],\n",
    "                'ankle_1': [6, 20],\n",
    "                'hip_2': [7, 21],\n",
    "                'ankle_2': [8, 22],\n",
    "                'hip_3': [9, 23],\n",
    "                'ankle_3': [10, 24],\n",
    "                'hip_4': [11, 25],\n",
    "                'ankle_4': [12, 26],\n",
    "            },\n",
    "            'action_position': {\n",
    "                'root': [],\n",
    "                'hip_1': [0],\n",
    "                'ankle_1': [1],\n",
    "                'hip_2': [2],\n",
    "                'ankle_2': [3],\n",
    "                'hip_3': [4],\n",
    "                'ankle_3': [5],\n",
    "                'hip_4': [6],\n",
    "                'ankle_4': [7],\n",
    "            },\n",
    "            'edge': [[0, 1], [0, 3], [0, 5], [0, 7], [1, 2], [3, 4], [5, 6], [7, 8]],\n",
    "        }\n",
    "    else:\n",
    "        raise NameError('agent name not valid, only \"hopper\", \"halfcheetah\" and \"walker2d\" are implemented')\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 225, 225])\n"
     ]
    }
   ],
   "source": [
    "agent = get_agent_config('ant')\n",
    "num_node = agent['num_node']\n",
    "max_length = 20\n",
    "prompt_length = 5\n",
    "structural_mask = get_structural_mask(agent, max_length, prompt_length)\n",
    "temporal_mask_list = get_temporal_mask_list(num_node, max_length, prompt_length)\n",
    "mask_store = []\n",
    "for temporal_mask in temporal_mask_list:\n",
    "    mask = structural_mask + temporal_mask\n",
    "    mask_store.append(mask)\n",
    "mask_store = torch.stack(mask_store, dim=0)\n",
    "print(mask_store.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 0, 1, 1, 0])\n",
    "a = torch.from_numpy(a).bool()\n",
    "b = np.array([0, 1, 1, 0, 0])\n",
    "b = torch.from_numpy(b).bool()\n",
    "~(~a + ~b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigate NaN in action\n",
    "mask is not right..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/workstation2/Yi-Hung/prompt-dt/test.ipynb Cell 23\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132382e322e3131362e323437222c2275736572223a22776f726b73746174696f6e32227d/home/workstation2/Yi-Hung/prompt-dt/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, np\u001b[39m.\u001b[39mnan])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223132382e322e3131362e323437222c2275736572223a22776f726b73746174696f6e32227d/home/workstation2/Yi-Hung/prompt-dt/test.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39misnan(x)\u001b[39m.\u001b[39many()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, np.nan])\n",
    "assert not torch.isnan(x).any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from prompt_dt.prompt_decision_transformer import PromptDecisionTransformer\n",
    "from prompt_dt.graph_prompt_decision_transformer import GPDT_V2_Torch\n",
    "# from prompt_dt.prompt_utils import get_agent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 560\n",
    "state_dim = 27\n",
    "act_dim = 8\n",
    "K = 20\n",
    "p_len = 5\n",
    "embed_dim = 128\n",
    "n_layer = 3\n",
    "n_head = 1\n",
    "dropout = 0.1\n",
    "agent_name = 'ant'\n",
    "agent = get_agent_config(agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866084\n"
     ]
    }
   ],
   "source": [
    "model = PromptDecisionTransformer(\n",
    "    state_dim=state_dim,\n",
    "    act_dim=act_dim,\n",
    "    max_length=K,\n",
    "    max_ep_len=1000,\n",
    "    hidden_size=embed_dim,\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_inner=4 * embed_dim,\n",
    "    activation_function='relu',\n",
    "    n_positions=1024,\n",
    "    resid_pdrop=dropout,\n",
    "    attn_pdrop=dropout,\n",
    ")\n",
    "                            # states, actions, rewards, returns_to_go, timesteps, attention_mask, prompt_states, prompt_actions, prompt_rewards, prompt_dones, prompt_returns_to_go, prompt_timesteps, prompt_attention_mask\n",
    "# summary(model, \n",
    "#         input_size = [(b_size, K, state_dim), (b_size, K, act_dim), (b_size, K, 1), (b_size, K, 1), (b_size, K), (b_size, K), (b_size, p_len, state_dim), (b_size, p_len, act_dim), (b_size, p_len, 1), (b_size, p_len, 1), (b_size, p_len, 1), (b_size, p_len), (b_size, p_len)],\n",
    "#         dtypes = [torch.float32, torch.float32, torch.float32, torch.float32, torch.int64, torch.float64, torch.float32, torch.float32, torch.float32, torch.float32, torch.float32, torch.int64, torch.float64],\n",
    "#         depth = 0,\n",
    "#         device = 'cpu')\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856962\n"
     ]
    }
   ],
   "source": [
    "model = GPDT_V2_Torch(\n",
    "    agent=agent,\n",
    "    max_length=K,\n",
    "    max_ep_length=1000,\n",
    "    prompt_length=p_len,\n",
    "    hidden_size=embed_dim,\n",
    "    n_layers=n_layer,\n",
    "    dropout=dropout,\n",
    ")\n",
    "# summary(model, \n",
    "#         input_size = [(64, 20, 17), (64, 21, 6), (64, 20, 1), (64, 20, 1), (64, 20), (64, 20)],\n",
    "#         dtypes = [torch.float32, torch.float32, torch.float32, torch.float32, torch.int64, torch.float64],\n",
    "#         depth = 0,\n",
    "#         device = 'cpu')\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(n_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch 2.0 compile test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0167,  1.0197,  1.1520,  0.5055,  1.1966, -1.3498,  0.0839,  1.3925,\n",
      "          1.4011,  1.3631],\n",
      "        [ 1.3073,  0.7412,  1.4141, -0.8988, -0.3289,  1.3362,  1.0690,  0.8997,\n",
      "          1.3311,  0.8283],\n",
      "        [ 1.2202,  0.6734,  0.6878,  0.2398, -1.0635,  1.3986,  0.9566,  0.9573,\n",
      "         -0.4506,  1.3072],\n",
      "        [ 1.4010, -0.1403,  0.6883,  0.7119,  0.0699,  0.8176,  1.3714,  1.2906,\n",
      "          1.4136, -0.3084],\n",
      "        [ 1.3427,  0.9271, -1.1760, -0.8434,  1.1494,  0.1401,  1.3093, -0.0803,\n",
      "         -0.5412,  1.0048],\n",
      "        [ 1.3966, -0.1594,  0.1448,  0.5719,  1.3931,  1.4101,  1.3929,  0.4363,\n",
      "         -0.3037,  0.4207],\n",
      "        [-0.5789, -0.0328,  1.2149,  0.7540,  1.4142,  0.8863,  0.9898,  0.5243,\n",
      "          1.2279, -1.1461],\n",
      "        [ 0.1016,  1.3345,  0.8952,  0.3761,  0.4474,  1.3854,  0.3412, -1.0334,\n",
      "          0.7773,  0.8762],\n",
      "        [ 1.3877, -0.2859,  1.3510,  0.2604,  1.3313,  1.4089, -1.4055,  0.3332,\n",
      "          1.3932,  0.4427],\n",
      "        [ 1.3954,  1.3670,  1.2527,  0.9427, -0.3774, -0.8923,  0.9188,  1.4115,\n",
      "         -1.0461, -0.0182]])\n"
     ]
    }
   ],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(x)\n",
    "    return a + b\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test wandb (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myihung\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/workstation2/Yi-Hung/prompt-dt/wandb/run-20230530_143031-prbpmpvh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yihung/my-awesome-project/runs/prbpmpvh' target=\"_blank\">super-cherry-2</a></strong> to <a href='https://wandb.ai/yihung/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yihung/my-awesome-project' target=\"_blank\">https://wandb.ai/yihung/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yihung/my-awesome-project/runs/prbpmpvh' target=\"_blank\">https://wandb.ai/yihung/my-awesome-project/runs/prbpmpvh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
